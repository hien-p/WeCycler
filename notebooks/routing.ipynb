{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f6b524-e60e-4f71-a377-47c640faed7f",
   "metadata": {},
   "source": [
    "# Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e90fdb4e-cb99-4b64-b95c-362e03be4535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable tracing at assess\n",
      "AI21 ready\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from botcore.setup import trace_ai21\n",
    "from botcore.utils.prompt_utils import build_prompt\n",
    "from botcore.routing.chat_route import ProductChatRouter\n",
    "MODEL = trace_ai21('assess')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7ea30-749c-4c1f-896e-197a22496b7a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8479d2-2a4a-468a-9845-fb3735e08ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "router = ProductChatRouter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760a29e-a3c8-492c-8341-382afdb15059",
   "metadata": {},
   "source": [
    "# Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a04968-c38f-4431-8269-6fea84ab911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['product', 'n_top']\n",
    "outputs = {\"questions\": \"a js array of questions\", \"chain\": \"always return 'electronic'\"}\n",
    "elec_template = \"\"\"You are well versed in {product}.\n",
    "You will need to list out {n_top} questions to ask about the condition of {product}.\n",
    "{format_instructions}\n",
    "Questions:\"\"\"\n",
    "\n",
    "elec_prompt = build_prompt(inputs, outputs, elec_template)\n",
    "\n",
    "outputs = {\"questions\": \"a js array of questions\", \"chain\": \"always return 'recyclable'\"}\n",
    "\n",
    "recyc_template = \"\"\"You are a secondhand dealer.\n",
    "You will need to list out {n_top} questions to ask about the condition of {product}.\n",
    "{format_instructions}\n",
    "Questions:\"\"\"\n",
    "\n",
    "recyc_prompt = build_prompt(inputs, outputs, recyc_template)\n",
    "\n",
    "elec_chain = LLMChain(llm=MODEL, prompt=elec_prompt)\n",
    "recyc_chain = LLMChain(llm=MODEL, prompt=recyc_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75417c88-5354-4808-bea3-6391dd60f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"electronic\",\n",
    "        \"description\": \"Good for answering questions about electronic.\",\n",
    "        \"chain\": elec_chain,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"recyclable\",\n",
    "        \"description\": \"Good for answering questions about recyclable.\",\n",
    "        \"chain\": recyc_chain,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    chain = p_info['chain']\n",
    "    destination_chains[name] = chain\n",
    "default_chain = recyc_chain\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c964f701-dab6-4228-a762-657a3f02f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "# print(MULTI_PROMPT_ROUTER_TEMPLATE)\n",
    "# router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "# print(router_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace74936-b26a-4452-9e07-6078df90f344",
   "metadata": {},
   "source": [
    "## Custom Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b54e133-e687-45f8-a80f-b1b2cd7bf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "from langchain.schema import OutputParserException\n",
    "from langchain.chains.router.llm_router import RouterOutputParser\n",
    "\n",
    "class ConditionRouterOutputParser(RouterOutputParser):\n",
    "    \"\"\"Parser for output of router chain int he multi-prompt chain.\"\"\"\n",
    "\n",
    "    default_destination: str = \"DEFAULT\"\n",
    "    \n",
    "    def parse(self, text: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            parsed = super().parse(text)\n",
    "            parsed[\"next_inputs\"]['n_top'] = parsed['n_top']\n",
    "            parsed[\"next_inputs\"]['product'] = parsed[\"product\"]\n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            raise OutputParserException(\n",
    "                f\"Parsing text\\n{text}\\n raised following error:\\n{e}\"\n",
    "            )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfbb3a1-7264-4096-a696-b46c24bbc3e8",
   "metadata": {},
   "source": [
    "## Custom template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84a407a2-3a26-488d-8ea4-777331689fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "    \"product\": string \\ the product mentioned in the original input\n",
    "    \"n_top\": {{n_top}}\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
    "REMEMBER: \"product\" can just be the original input if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT >>\"\"\"\n",
    "router_template = template.format(destinations=destinations_str)\n",
    "\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "\n",
    "# print(router_template)\n",
    "router_prompt = PromptTemplate(template=router_template, input_variables=[\"input\", \"n_top\"], output_parser=ConditionRouterOutputParser())\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(MODEL, router_prompt)\n",
    "\n",
    "cond_chain = MultiPromptChain(router_chain=router_chain, destination_chains=destination_chains,\n",
    "                         default_chain=default_chain, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ec99c5f-70af-4810-aa76-5f19a05d93b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "recyclable: {'input': 'shirt', 'n_top': 3, 'product': 'shirt'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'shirt',\n",
       " 'n_top': 3,\n",
       " 'product': 'shirt',\n",
       " 'text': '\\n```\\n[\\n \"Is the shirt in good condition?\",\\n \"Is the shirt stained?\",\\n \"Is the shirt torn?\"\\n]\\n```\\nChain:\\n```\\nrecyclable\\n```'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(cond_chain)\n",
    "# print(cond_chain.input_keys) \n",
    "ans = cond_chain({\"input\": \"I have a shirt\", \"n_top\": 3})\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9f81efa-64fb-46ea-b795-1ce555b7cf80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10603/411879537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ans' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
