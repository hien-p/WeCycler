{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9b0d1e-d81b-40ad-bb02-ab09afc93170",
   "metadata": {},
   "source": [
    "# Agent chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d158db71-07c8-4eab-8781-9f6865365fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable tracing at vechai\n",
      "AI21 ready\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from botcore.setup import trace_ai21\n",
    "MODEL = trace_ai21('vechai')\n",
    "\n",
    "\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from botcore.chains.assess_usage import build_assess_usage_tool\n",
    "from botcore.chains.pros_cons import build_pros_cons_tool\n",
    "\n",
    "\n",
    "class AgentBot:\n",
    "\n",
    "    def __init__(self, model: BaseLLM, memory):\n",
    "        tools = self.load_tools(model, memory)\n",
    "        self.agent = initialize_agent(tools, model,\\\n",
    "                                      agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\\\n",
    "                                      verbose=True, return_intermediate_steps=True)\n",
    "        print(\"Agent is ready\")\n",
    "        \n",
    "        \n",
    "    def load_tools(self, model, memory):\n",
    "        tools = [build_assess_usage_tool(model,memory),\n",
    "                 build_pros_cons_tool(model,memory)]\n",
    "        return tools\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f66cad5-4557-4a53-96f6-fefd09c17a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent is ready\n"
     ]
    }
   ],
   "source": [
    "from botcore.utils.memory_utils import QAMemory\n",
    "data = {\n",
    "  \"title\": \"Old phone\",\n",
    "  \"features\": [\n",
    "    \"What is the screen size? 2.8 inches\",\n",
    "    \"What is the RAM size? 512 MB\",\n",
    "    \"What is the storage capacity? 4 GB\",\n",
    "    \"What is the battery capacity? 1500 mAh\",\n",
    "    \"Is there any malfunction or defect? yes\",\n",
    "    \"What is the current physical condition of the product? excellent\",\n",
    "    \"Is the product still under warranty? yes\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "ques = [i.split(\"?\")[0] for i in data['features']]\n",
    "ans = [i.split(\"?\")[1] for i in data['features']]\n",
    "qa_mem = QAMemory('question')\n",
    "qa_mem.load_qa_to_memory(ques, ans)\n",
    "agent = AgentBot(MODEL, qa_mem.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3990d65-f539-4d5b-bb0f-f87b9232f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I will assess its usability\n",
      "Action: assess_usage\n",
      "Action Input: my product\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a secondhand dealer and assessing the user's product. Based on your questions and user answers from the chat history.\n",
      " AI: What is the screen size\n",
      "Human:  2.8 inches\n",
      "AI: What is the RAM size\n",
      "Human:  512 MB\n",
      "AI: What is the storage capacity\n",
      "Human:  4 GB\n",
      "AI: What is the battery capacity\n",
      "Human:  1500 mAh\n",
      "AI: Is there any malfunction or defect\n",
      "Human:  yes\n",
      "AI: What is the current physical condition of the product\n",
      "Human:  excellent\n",
      "AI: Is the product still under warranty\n",
      "Human:  yes\n",
      " Please give your best answer for the given question from the user.\n",
      " The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"useable\": string  // Is the given product still useable.\n",
      "\t\"reason\": string  // A reason why the product is useable or not useable.\n",
      "\t\"function\": string  // Assess how well the given product still can function.\n",
      "}\n",
      "```\n",
      " Question: my product.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\n",
      "{\n",
      "  \"useable\": \"yes\",\n",
      "  \"reason\": \"excellent\",\n",
      "  \"function\": \"excellent\"\n",
      "}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know my product's usability\n",
      "Final Answer: yes\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Is my product usable?',\n",
       " 'output': 'yes',\n",
       " 'intermediate_steps': [(AgentAction(tool='assess_usage', tool_input='my product', log=' I will assess its usability\\nAction: assess_usage\\nAction Input: my product'),\n",
       "   '\\n{\\n  \"useable\": \"yes\",\\n  \"reason\": \"excellent\",\\n  \"function\": \"excellent\"\\n}')]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = agent.agent(\"Is my product usable?\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d0346b-39d4-4c62-a28b-500ef4d27428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input', 'output', 'intermediate_steps'])\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "print(a.keys())\n",
    "print(a['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0667610c-4948-49ba-84f9-8069cac16022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AgentAction(tool='assess_usage', tool_input='is the product recyclable', log=' I should consider if the product is recyclable\\nAction: assess_usage\\nAction Input: is the product recyclable'),\n",
       " '\\n{\\n  \"useable\": \"yes\",\\n  \"reason\": \"The product is made of recyclable materials.\",\\n  \"function\": \"The product can function as well as new.\"\\n}')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['intermediate_steps'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8885ba1d-5436-41a4-9a0b-76f0a6988376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentAction(tool='assess_usage', tool_input='is the product recyclable', log=' I should consider if the product is recyclable\\nAction: assess_usage\\nAction Input: is the product recyclable')\n",
      "\n",
      "{\n",
      "  \"useable\": \"yes\",\n",
      "  \"reason\": \"The product is made of recyclable materials.\",\n",
      "  \"function\": \"The product can function as well as new.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(a['intermediate_steps'][0][0])\n",
    "print(a['intermediate_steps'][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7119675c-2c97-45f7-960f-408dc5fa7ce8",
   "metadata": {},
   "source": [
    "# RUN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ffe2b0f-acef-49ac-9d18-12fed6857793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable tracing at vechai\n",
      "AI21 ready\n",
      "Load done\n",
      "Agent is ready\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from botcore.setup import trace_ai21\n",
    "from botcore.bot_agent import AgentBot\n",
    "from botcore.utils.memory_utils import QAMemory\n",
    "\n",
    "data = {\n",
    "  \"title\": \"Old phone\",\n",
    "  \"features\": [\n",
    "    \"What is the screen size? 2.8 inches\",\n",
    "    \"What is the RAM size? 512 MB\",\n",
    "    \"What is the storage capacity? 4 GB\",\n",
    "    \"What is the battery capacity? 1500 mAh\",\n",
    "    \"Is there any malfunction or defect? yes\",\n",
    "    \"What is the current physical condition of the product? excellent\",\n",
    "    \"Is the product still under warranty? yes\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "MODEL = trace_ai21()\n",
    "\n",
    "ques = [i.split(\"?\")[0] for i in data['features']]\n",
    "ans = [i.split(\"?\")[1] for i in data['features']]\n",
    "qa_mem = QAMemory('question')\n",
    "\n",
    "\n",
    "qa_mem.load_all(data['title'], ques, ans)\n",
    "agent = AgentBot(MODEL, qa_mem.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d273b74c-9e41-4a1a-9840-611969ef24aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should give recycling tips\n",
      "Action: recycling_tip\n",
      "Action Input: product\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a secondhand dealer and assessing the user's product. Based on your questions and user answers from the chat history.\n",
      " Human: I have this used Old phone of mine. Please ask me some questions about it.\n",
      "AI: What is the screen size\n",
      "Human:  2.8 inches\n",
      "AI: What is the RAM size\n",
      "Human:  512 MB\n",
      "AI: What is the storage capacity\n",
      "Human:  4 GB\n",
      "AI: What is the battery capacity\n",
      "Human:  1500 mAh\n",
      "AI: Is there any malfunction or defect\n",
      "Human:  yes\n",
      "AI: What is the current physical condition of the product\n",
      "Human:  excellent\n",
      "AI: Is the product still under warranty\n",
      "Human:  yes\n",
      " Given a question: product.\n",
      " Please give your best answer:\n",
      " The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"tips\": string  // a js array of recycling actions for the product mentioned in the chat history. This array'length should be larger than 3.\n",
      "\t\"effect\": string  // a helpful explanation for the advantages of recycling the product mentioned in the chat history.\n",
      "}\n",
      "```.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m\n",
      "{\n",
      "  \"tips\": [\n",
      "    \"The phone can be donated to charity or sold online.\",\n",
      "    \"The phone can be recycled for its parts.\",\n",
      "    \"The phone can be refurbished and resold.\"\n",
      "  ],\n",
      "  \"effect\": \"By recycling the phone, you can help reduce waste and conserve resources.\"\n",
      "}\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: ` \nBy recycling the phone, you can help reduce waste and conserve resources.`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3721/900719592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"How can I recycle my product\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_only_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/code/WeCycler/notebooks/../botcore/bot_agent.py\u001b[0m in \u001b[0;36manswer\u001b[0;34m(self, question, return_only_output)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_only_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_only_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m    958\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0mraise_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_parsing_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m    763\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mfull_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     async def aplan(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/mrkl/output_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"Action\\s*\\d*\\s*:[\\s]*(.*?)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             raise OutputParserException(\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0;34mf\"Could not parse LLM output: `{text}`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobservation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Invalid Format: Missing 'Action:' after 'Thought:'\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: ` \nBy recycling the phone, you can help reduce waste and conserve resources.`"
     ]
    }
   ],
   "source": [
    "a = agent.answer(\"How can I recycle my product\", return_only_output=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "913df942-718c-4cb7-a2ee-d37d549ef026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can recycle paper by tearing it into small pieces and adding it to my compost pile.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95833b2-ce4b-4a9b-a320-9823095943d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n  \"tips\": [\\n    \"The phone can be donated to charity or sold online.\",\\n    \"The phone can be recycled for its parts.\",\\n    \"The phone can be refurbished and resold.\"\\n  ],\\n  \"effect\": \"By recycling the phone, you can help reduce waste and conserve resources.\"\\n}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
