{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a06b895-c401-4879-9bb1-ecbaf0e4e7a5",
   "metadata": {},
   "source": [
    "# Recycling chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4dd30ba-77e6-4808-ac50-511d15a5c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load done\n",
      "Enable tracing at vechai\n",
      "AI21 ready\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from botcore.utils.memory_utils import load_sample_qa, QAMemory\n",
    "from botcore.setup import trace_ai21\n",
    "ques, ans = load_sample_qa()\n",
    "mem = QAMemory('question')\n",
    "mem.load_all('GPU',ques, ans)\n",
    "MODEL = trace_ai21()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19946e3e-06a4-431a-a49a-5dbaf86ef7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECYCLING_TIP_TOOL = {\"desc\": \"Good for answering questions about recycling tips.\", \"name\":\"recycling_tip\"}\n",
    "RECYCLING_TIP_CONST =\\\n",
    "{\"inputs\": [\"chat_history\", \"question\"],\n",
    " \"outputs\": {\"tips\": \"a js array of recycling actions for the product mentioned in the chat history. This array'length should be larger than 3.\",\n",
    "             \"effect\": \"a helpful explanation for the advantages of recycling the product mentioned in the chat history.\"},\n",
    " 'template': \"\"\"You are a secondhand dealer and assessing the user's product. Based on your questions and user answers from the chat history.\n",
    " {chat_history}\n",
    " Given a question: {question}.\n",
    " Please give your best answer:\n",
    " {format_instructions}.\"\"\"}\n",
    "\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain import LLMChain\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(f'../')\n",
    "from botcore.utils.prompt_utils import build_prompt\n",
    "from langchain.memory.chat_memory import BaseChatMemory\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def build_recycling_tip_chain(model: BaseLLM, memory: BaseChatMemory):\n",
    "    \"\"\"\n",
    "    Chain is designed to answer questions about pros and cons.\n",
    "    Input: chain({\"question\": question})\n",
    "    \"\"\"\n",
    "    inputs = RECYCLING_TIP_CONST['inputs']\n",
    "    outputs = RECYCLING_TIP_CONST['outputs']\n",
    "    template = RECYCLING_TIP_CONST['template']\n",
    "    prompt = build_prompt(inputs, outputs, template)\n",
    "    chain = LLMChain(llm=model, verbose=True, prompt=prompt, memory=memory)\n",
    "    return chain\n",
    "\n",
    "def build_recycling_tip_tool(model: BaseLLM, memory: BaseChatMemory):\n",
    "    name = RECYCLING_TIP_TOOL['name']\n",
    "    desc = RECYCLING_TIP_TOOL['desc']\n",
    "    chain = build_pros_cons_chain(model, memory)\n",
    "    func = lambda question: chain.run(question)\n",
    "    tool = Tool.from_function(func=func, name=name, description=desc)\n",
    "    return tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d67cca5c-b1fa-48e5-ba1a-72c33bc107d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a secondhand dealer and assessing the user's product. Based on your questions and user answers from the chat history.\n",
      " Human: I have this used PC of mine. Please ask me some questions about it.\n",
      "AI: What is the screen size\n",
      "Human:  2.8 inches\n",
      "AI: What is the RAM size\n",
      "Human:  512 MB\n",
      "AI: What is the storage capacity\n",
      "Human:  4 GB\n",
      "AI: What is the battery capacity\n",
      "Human:  1500 mAh\n",
      "AI: Is there any malfunction or defect\n",
      "Human:  yes\n",
      "AI: What is the current physical condition of the product\n",
      "Human:  excellent\n",
      "AI: Is the product still under warranty\n",
      "Human:  yes\n",
      "Human: How can I recycle it\n",
      "AI: \n",
      " Answer: You can recycle it by taking it to a recycling center.\n",
      " Question: What are the benefits of recycling it.\n",
      " Answer: By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.\n",
      "Human: How can I recycle it\n",
      "AI:  You can recycle it by taking it to a recycling center.\n",
      " Question: What are the benefits of recycling it.\n",
      " Response: By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.\n",
      "Human: How can I recycle it\n",
      "AI: \n",
      "\n",
      "```\n",
      "{\n",
      "  \"tips\": \"Take it to a recycling center.\",\n",
      "  \"effect\": \"By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.\"\n",
      "}\n",
      " Given a question: How can I recycle it.\n",
      " Please give your best answer:\n",
      " The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"tips\": string  // a js array of recycling actions for the product mentioned in the chat history. This array'length should be larger than 3.\n",
      "\t\"effect\": string  // a helpful explanation for the advantages of recycling the product mentioned in the chat history.\n",
      "}\n",
      "```.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How can I recycle it',\n",
       " 'chat_history': 'Human: I have this used PC of mine. Please ask me some questions about it.\\nAI: What is the screen size\\nHuman:  2.8 inches\\nAI: What is the RAM size\\nHuman:  512 MB\\nAI: What is the storage capacity\\nHuman:  4 GB\\nAI: What is the battery capacity\\nHuman:  1500 mAh\\nAI: Is there any malfunction or defect\\nHuman:  yes\\nAI: What is the current physical condition of the product\\nHuman:  excellent\\nAI: Is the product still under warranty\\nHuman:  yes\\nHuman: How can I recycle it\\nAI: \\n Answer: You can recycle it by taking it to a recycling center.\\n Question: What are the benefits of recycling it.\\n Answer: By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.\\nHuman: How can I recycle it\\nAI:  You can recycle it by taking it to a recycling center.\\n Question: What are the benefits of recycling it.\\n Response: By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.\\nHuman: How can I recycle it\\nAI: \\n\\n```\\n{\\n  \"tips\": \"Take it to a recycling center.\",\\n  \"effect\": \"By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.\"\\n}',\n",
       " 'text': '\\n\\n```\\n{\\n  \"tips\": [\\n    \"Take it to a recycling center.\",\\n    \"Find a recycling center near you.\",\\n    \"Contact your local recycling center.\"\\n  ],\\n  \"effect\": \"By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.\"\\n}'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = build_recycling_tip_chain(MODEL, mem.memory)\n",
    "\n",
    "ans = chain({\"question\": \"How can I recycle it\"})\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9f35dfa-5cab-4d07-a711-e888e93ac715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How can I recycle it',\n",
       " 'chat_history': 'Human: I have this used PC of mine. Please ask me some questions about it.\\nAI: What is the screen size\\nHuman:  2.8 inches\\nAI: What is the RAM size\\nHuman:  512 MB\\nAI: What is the storage capacity\\nHuman:  4 GB\\nAI: What is the battery capacity\\nHuman:  1500 mAh\\nAI: Is there any malfunction or defect\\nHuman:  yes\\nAI: What is the current physical condition of the product\\nHuman:  excellent\\nAI: Is the product still under warranty\\nHuman:  yes\\nHuman: How can I recycle it\\nAI: \\n Answer: You can recycle it by taking it to a recycling center.\\n Question: What are the benefits of recycling it.\\n Answer: By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.\\nHuman: How can I recycle it\\nAI:  You can recycle it by taking it to a recycling center.\\n Question: What are the benefits of recycling it.\\n Response: By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.',\n",
       " 'text': '\\n\\n```\\n{\\n  \"tips\": \"Take it to a recycling center.\",\\n  \"effect\": \"By recycling it, you can reduce the need for raw materials, save energy, and reduce greenhouse gas emissions.\"\\n}'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
